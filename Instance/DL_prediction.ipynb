{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07f52b7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load required packages\n",
    "import optuna\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from lightgbm import LGBMRegressor\n",
    "from tensorflow.keras.optimizers import Adam, SGD, RMSprop\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, GRU, Bidirectional\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "from sklearn.metrics import mean_squared_error, r2_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2e1998c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_result(y_valid, y_pred, filepath):\n",
    "    r2 = pd.DataFrame({'True Value': y_valid,'Prediction Value': y_pred})\n",
    "    r2.to_csv(filepath,index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a5bf3a9",
   "metadata": {},
   "source": [
    "# 1. Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b9a3604",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load phenotype label\n",
    "gw = pd.read_csv('gw.csv', index_col=0)\n",
    "gl = pd.read_csv('gl.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277619c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load gsctool features\n",
    "dataA_features = pd.read_csv('dataA.gsc.csv',index_col=0)\n",
    "dataB_features = pd.read_csv('dataB.gsc.csv',index_col=0)\n",
    "dataC_features = pd.read_csv('dataC.gsc.csv',index_col=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bff7ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataA_features.index.name = 'Run'\n",
    "dataB_features.index.name='Run'\n",
    "dataC_features.index.name = 'Sample Name'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bc6174",
   "metadata": {},
   "outputs": [],
   "source": [
    "# merge featuers ann label\n",
    "gw_dataA = pd.merge(gw.iloc[:, 1], dataA_features, on = 'Run').dropna()\n",
    "gw_dataB = pd.merge(gw.iloc[:, 1], dataB_features, on = 'Run').dropna()\n",
    "gw_dataC = pd.merge(gw.iloc[:, [0,1]], dataC_features, on = 'Sample Name').set_index('Sample Name').dropna()\n",
    "gl_dataA = pd.merge(gl.iloc[:, 1], dataA_features, on = 'Run').dropna()\n",
    "gl_dataB = pd.merge(gl.iloc[:, 1], dataB_features, on = 'Run').dropna()\n",
    "gl_dataC = pd.merge(gl.iloc[:, [0,1]], dataC_features, on = 'Sample Name').set_index('Sample Name').dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2aaee0e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "gl_dataA_value = gl_dataA.iloc[:, 1:].values\n",
    "gl_dataA_label = gl_dataA.iloc[:, 0].values\n",
    "gl_dataB_value = gl_dataB.iloc[:, 1:].values\n",
    "gl_dataB_label = gl_dataB.iloc[:, 0].values\n",
    "gl_dataC_value = gl_dataC.iloc[:, 1:].values\n",
    "gl_dataC_label = gl_dataC.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb6fca4",
   "metadata": {},
   "outputs": [],
   "source": [
    "gw_dataA_value = gw_dataA.iloc[:, 1:].values\n",
    "gw_dataA_label = gw_dataA.iloc[:, 0].values\n",
    "gw_dataB_value = gw_dataB.iloc[:, 1:].values\n",
    "gw_dataB_label = gw_dataB.iloc[:, 0].values\n",
    "gw_dataC_value = gw_dataC.iloc[:, 1:].values\n",
    "gw_dataC_label = gw_dataC.iloc[:, 0].values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "679711f3",
   "metadata": {},
   "source": [
    "# 2 lightGBM + Optuna\n",
    "The following example is grain length predictions of dataA, which can be replaced with other phenotypes of other data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1274967a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training and testing data\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = np.concatenate([X_train, X_part], 0)\n",
    "            y_train = np.concatenate([y_train, y_part], 0)\n",
    "    return X_train, y_train, X_valid, y_valid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6d01b8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = get_k_fold_data(5,1,gl_dataA_value,gl_dataA_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "92646491",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optuna search the best hyperparameter \n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'metric': 'mse', \n",
    "        \"boosting_type\": \"gbdt\",                \n",
    "        \"seed\": 42,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_estimators\": trial.suggest_int('n_estimators', 100, 1000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "    }\n",
    "    \n",
    "    lgb=LGBMRegressor(**param)\n",
    "    lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "    return lgb.score(X_valid, y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a00d6e56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Search the best hyperparameter\n",
    "optuna.logging.set_verbosity(optuna.logging.WARNING) # 压缩报告信息\n",
    "study_tuner = optuna.create_study(direction='maximize')\n",
    "study_tuner.optimize(objective, n_trials=100) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a70ea178",
   "metadata": {},
   "outputs": [],
   "source": [
    "# exhibit the beat hyperparameter\n",
    "trial = study_tuner.best_trial\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0b49039",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod the best hyperparameter\n",
    "def objective(trial):\n",
    "    param = {\n",
    "        'metric': 'mse', \n",
    "        \"boosting_type\": \"gbdt\",                \n",
    "        \"seed\": 42,\n",
    "        \"verbosity\": -1,\n",
    "        \"n_estimators\": trial.suggest_int('n_estimators', 100, 1000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.3),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 12),\n",
    "        'num_leaves': trial.suggest_int('num_leaves', 2, 512),\n",
    "        'min_child_samples': trial.suggest_int('min_child_samples', 1, 100),\n",
    "        'feature_fraction': trial.suggest_uniform('feature_fraction', 0.1, 1.0),\n",
    "        'bagging_fraction': trial.suggest_uniform('bagging_fraction', 0.1, 1.0),\n",
    "        'lambda_l1': trial.suggest_loguniform('lambda_l1', 1e-8, 10.0),\n",
    "        'lambda_l2': trial.suggest_loguniform('lambda_l2', 1e-8, 10.0),\n",
    "    }\n",
    "    \n",
    "    lgb=LGBMRegressor(**param)\n",
    "    model = lgb.fit(X_train, y_train, eval_set=[(X_valid, y_valid)])\n",
    "    y_pred = model.predict(X_valid)\n",
    "    return lgb, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "940a1331",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model with the best hyperparameter\n",
    "lgb, y_pred = objective(study_tuner.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8053c3d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predict result, which can be used for evaluate the performance of model\n",
    "save_result(y_valid,y_pred, 'tmp.lgb.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17a16bb1",
   "metadata": {},
   "source": [
    "# 3 GRU + Optuna\n",
    "The following example is a grain length prediction for dataA\n",
    "1. Dataset can be replaced\n",
    "2. GRU can be replaced by BiGRU"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4ece959",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split the training and testing data\n",
    "def get_k_fold_data(k, i, X, y):\n",
    "    assert k > 1\n",
    "    fold_size = X.shape[0] // k\n",
    "    X_train, y_train = None, None\n",
    "    for j in range(k):\n",
    "        idx = slice(j * fold_size, (j + 1) * fold_size)\n",
    "        X_part, y_part = X[idx, :], y[idx]\n",
    "        if j == i:\n",
    "            X_valid, y_valid = X_part, y_part\n",
    "        elif X_train is None:\n",
    "            X_train, y_train = X_part, y_part\n",
    "        else:\n",
    "            X_train = np.concatenate([X_train, X_part], 0)\n",
    "            y_train = np.concatenate([y_train, y_part], 0)\n",
    "    return X_train.reshape(-1,1,X_train.shape[1]).astype(np.float32), y_train.astype(np.float32), X_valid.reshape(-1,1,X_train.shape[1]).astype(np.float32), y_valid.astype(np.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8ea646d",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, y_train, X_valid, y_valid = get_k_fold_data(5,1,gl_dataA_value,gl_dataA_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a871fd87",
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective(trial):\n",
    "    # Parameters\n",
    "    L2 = trial.suggest_float(\"l\", 1e-5, 1e-2, log=True)\n",
    "    BATCH_SIZE = trial.suggest_int(\"batch_size\", 16, 128, step=8)\n",
    "    EPOCHS = trial.suggest_int(\"epochs\", 10,100, step=10)\n",
    "    LR = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    OPT = trial.suggest_categorical(\"optimizer\", [Adam, SGD, RMSprop])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=64, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(l=L2)))\n",
    "    model.add(GRU(units=64, return_sequences=True, kernel_regularizer=tf.keras.regularizers.l2(l=L2)))\n",
    "    model.add(GRU(units=32))\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=OPT(learning_rate=LR), loss='mse', metrics=['mae'])\n",
    "\n",
    "    H = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCHS, batch_size=BATCH_SIZE)\n",
    "    y_pred = model.predict(X_valid).reshape(y_valid.shape[0],)\n",
    "    return r2_score(y_valid,y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b739a48",
   "metadata": {},
   "outputs": [],
   "source": [
    "study = optuna.create_study(direction='maximize')\n",
    "study.optimize(objective, n_trials=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea5f5e9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "trial = study.best_trial\n",
    "print('Accuracy: {}'.format(trial.value))\n",
    "print(\"Best hyperparameters: {}\".format(trial.params))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9b3983c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# laod the best hyperparameter\n",
    "def objective(trial):\n",
    "    # Parameters\n",
    "    L2 = trial.suggest_float(\"l\", 1e-5, 1e-2, log=True)\n",
    "    BATCH_SIZE = trial.suggest_int(\"batch_size\", 16, 128, step=8)\n",
    "    EPOCHS = trial.suggest_int(\"epochs\", 10,100, step=10)\n",
    "    LR = trial.suggest_float(\"learning_rate\", 1e-5, 1e-2, log=True)\n",
    "    OPT = trial.suggest_categorical(\"optimizer\", [Adam, SGD, RMSprop])\n",
    "    \n",
    "    model = Sequential()\n",
    "    model.add(GRU(units=128, return_sequences=True, kernel_regularizer = tf.keras.regularizers.l2(l=L2)))\n",
    "    model.add(GRU(units=64,return_sequences=True, kernel_regularizer = tf.keras.regularizers.l2(l=L2)))\n",
    "    model.add(GRU(units=32))\n",
    "    model.add(Dense(16, activation=\"relu\"))\n",
    "    model.add(Dense(1))\n",
    "\n",
    "    model.compile(optimizer=OPT(learning_rate=LR), loss='mse', metrics=['mae'])\n",
    "\n",
    "    H = model.fit(X_train, y_train, validation_data=(X_valid, y_valid), epochs=EPOCHS, batch_size = BATCH_SIZE)\n",
    "    y_pred = model.predict(X_valid).reshape(y_valid.shape[0],)\n",
    "\n",
    "    return H, y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55d5ad67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the model with the best hyperparameter\n",
    "model, y_pred = objective(study.best_trial)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6c80bab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save the predict result, which can be used for evaluate the performance of model\n",
    "save_result(y_valid, y_pred, 'tmp.gru.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a49e0881",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
